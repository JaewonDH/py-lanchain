# py-lanchain


# https://ollama.com/ 에서 llama3.2:1b 모델을 다운받아서 모델을 구동한다. 
# ChatOllama 사용해서 로컬 PC에서 LLM 사용할 수 있다.